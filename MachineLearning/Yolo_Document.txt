Reconocimiento Automático de Placas Vehiculares mediante YOLO y OCR
1. Introducción
El Reconocimiento Automático de Placas Vehiculares (ALPR, por sus siglas en inglés Automatic License Plate Recognition) es una tecnología fundamental en sistemas modernos de movilidad inteligente, seguridad vial y gestión de accesos. Este sistema combina dos etapas clave: (1) la detección de la placa vehicular en una imagen o flujo de video, y (2) el reconocimiento del texto contenido en dicha placa mediante técnicas de visión por computadora y procesamiento de lenguaje.

En este trabajo se propone una solución basada en el modelo de detección de objetos YOLOv8 (You Only Look Once v8) y el motor de reconocimiento óptico de caracteres Tesseract OCR. Esta combinación permite lograr alta precisión y rendimiento en tiempo real, facilitando su integración en aplicaciones como peajes automáticos, control de accesos, estacionamientos inteligentes y sistemas de vigilancia urbana.

2. Fundamentos Teóricos
2.1 Visión por Computadora y Aprendizaje Profundo
El sistema se sustenta en redes neuronales convolucionales (CNNs) entrenadas mediante aprendizaje supervisado. A partir de un conjunto de imágenes etiquetadas, el modelo aprende a identificar patrones visuales característicos de las placas vehiculares, independientemente de factores como el ángulo de visión, la iluminación o el entorno circundante.

2.2 YOLOv8 para Detección de Objetos
YOLOv8, desarrollado por Ultralytics, es un algoritmo de detección de objetos de última generación que procesa toda la imagen en una única pasada, prediciendo simultáneamente las coordenadas de las cajas delimitadoras y las clases correspondientes. Sus ventajas incluyen:

Alta velocidad de inferencia (hasta 100+ FPS en GPU).
Precisión competitiva medida en mAP (mean Average Precision).
Soporte nativo para entrenamiento personalizado y exportación a formatos eficientes (ONNX, TensorRT).
2.3 Reconocimiento Óptico de Caracteres (OCR)
Una vez localizada la placa, se extrae la región de interés (ROI) y se aplica Tesseract OCR, un motor de código abierto ampliamente utilizado. Para maximizar la precisión del reconocimiento, se recomienda:

Aplicar preprocesamiento de la imagen (binarización, corrección de perspectiva, eliminación de ruido).
Configurar parámetros específicos como --psm 8 (modo de una sola palabra) y limitar el conjunto de caracteres permitidos según el formato nacional de placas.
2.4 Dataset y Anotación
La calidad del modelo depende directamente de la diversidad y representatividad del conjunto de datos. Se requieren imágenes que cubran variaciones en:

Iluminación (día, noche, contraluz).
Ángulos de captura (frontal, lateral, inclinado).
Estados de la placa (limpia, sucia, parcialmente oculta).
Formatos regionales (diferentes países o jurisdicciones).
Las imágenes deben ser anotadas en formato YOLO, donde cada archivo de etiqueta (.txt) contiene una línea por objeto con la estructura:
<class_id> <x_center> <y_center> <width> <height>
(coordenadas normalizadas entre 0 y 1).

Herramientas como LabelImg o Roboflow facilitan este proceso y permiten aplicar técnicas de aumento de datos (data augmentation).

2.5 Evaluación del Modelo
El desempeño del sistema se evalúa mediante métricas estándar:

mAP@0.5 : precisión promedio con umbral de IoU (Intersection over Union) ≥ 0.5.
Recall: proporción de placas reales correctamente detectadas.
Precisión del OCR: porcentaje de caracteres correctamente reconocidos respecto al total.
FPS (Frames por segundo): indicador de capacidad para operar en tiempo real.
3. Metodología de Implementación
3.1 Preparación del Dataset
Se organizó el conjunto de datos en la siguiente estructura:


dataset/
├── images/
│   ├── train/
│   └── val/
└── labels/
    ├── train/
    └── val/
Se definió un archivo de configuración placas.yaml:

train: dataset/images/train
val: dataset/images/val
nc: 1
names: ['placa']
3.2 Entrenamiento del Modelo YOLOv8
Se utilizó la librería ultralytics en Python. El modelo base yolov8n.pt (versión "nano") fue elegido por su equilibrio entre velocidad y precisión, aunque se recomienda yolov8s.pt o yolov8m.pt para entornos con mayor capacidad computacional.


from ultralytics import YOLO

model = YOLO('yolov8n.pt')
model.train(
    data='placas.yaml',
    epochs=100,
    imgsz=640,
    batch=16
)
El entrenamiento se realizó en una GPU NVIDIA, logrando convergencia en aproximadamente 2–4 horas, dependiendo del tamaño del dataset.

3.3 Integración con Tesseract OCR
Tras la detección, se recorta la región de la placa y se aplica preprocesamiento para mejorar la legibilidad:

import cv2
import pytesseract

def preprocess_plate(roi):
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    thresh = cv2.adaptiveThreshold(
        gray, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY, 11, 2
    )
    return thresh

# Configuración OCR para placas alfanuméricas
config = '--psm 8 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'
text = pytesseract.image_to_string(preprocess_plate(plate_roi), config=config).strip()
3.4 Sistema Completo de Inferencia
El flujo completo incluye:

Captura de imagen (desde archivo, cámara o stream de video).
Detección de placa con YOLOv8.
Recorte y preprocesamiento de la ROI.
Extracción de texto con Tesseract.
Validación y registro del resultado.
Este pipeline puede integrarse con módulos externos de:

Gestión de pagos (ej. validación de suscripción en estacionamientos).
Notificaciones (alertas ante placas en listas negras).
Almacenamiento (base de datos + respaldo en la nube).
4. Limitaciones del Sistema
A pesar de su eficacia, el sistema presenta ciertas limitaciones:

Condiciones de iluminación adversas (reflejos, oscuridad) reducen la precisión tanto en detección como en OCR.
Placas deterioradas, sucias o parcialmente ocultas pueden no ser detectadas o generar errores de lectura.
Variabilidad en formatos internacionales exige adaptación del modelo OCR según la región.
Requisitos de hardware: para operación en tiempo real con múltiples cámaras, se recomienda el uso de GPU o aceleradores dedicados (ej. NVIDIA Jetson).
5. Aplicaciones y Perspectivas Futuras
El sistema ALPR propuesto es escalable y adaptable a múltiples escenarios:

Peajes y accesos controlados: procesamiento automático sin intervención humana.
Seguridad ciudadana: cruce con bases de datos de vehículos robados o buscados.
Gestión de flotas: registro automático de entradas y salidas en instalaciones logísticas.
Ciudades inteligentes: integración con plataformas de movilidad para análisis de tráfico y planificación urbana.
Futuras mejoras incluyen:

Uso de EasyOCR o modelos OCR entrenados específicamente para fuentes de placas.
Implementación de corrección de perspectiva automática para placas inclinadas.
Despliegue en dispositivos edge mediante cuantización del modelo y uso de TensorRT.
6. Conclusiones
La combinación de YOLOv8 para detección de objetos y Tesseract OCR para reconocimiento de texto constituye una solución robusta, eficiente y de bajo costo para el reconocimiento automático de placas vehiculares. Su desempeño depende críticamente de la calid
